#cfg_sample_pspnet_cap_pretrain.yaml

padding_mode: 'cap_pretrain' # 'zeros', 'reflect', 'replicate', 'circular', 'partial', 'cap_pretrain', 'cap_train' or 'pp-pad'

# path for PSPNet.py
dataset: './dataset/VOCdevkit/VOC2012/'
pretrain: ['ADE', './weights/pspnet50_ADE20K.pth']
#pretrain: ['VOC', './weights/pspnet_zeros_best.pth'] #for pp-pad, partial as pretrain model with 0 padding
#pretrain: ['VOC', './outputs/pspnet_cap_pretrain_best.pth'] # for cap_train. weight file by cap_pretrain
outputs: './outputs/'

# training parameters
num_epochs: 160
val_output_interval: 5
batch_size: 6
batch_multiplier: 4
optimizer: 'adam' # 'adam' for cap_train, 'sgd' for others
# Reference range for pp-pad is specified in models/pppad.py: REF_PPPAD

# path for segment_val.py
# val_images: './val_100.npy'
# weights: ['VOC', './outputs/pspnet_cap_pretrain_best.pth']

# image sizes
input_size: 512 # 512 for CAP, 475 for others
expanded_size: 1050 # input image is first expanded to expanded_size, and then crop the image in input_size.
patch_stride: 47

# dataset info
color_mean: [0.485, 0.456, 0.406]
color_std: [0.229, 0.224, 0.225]
