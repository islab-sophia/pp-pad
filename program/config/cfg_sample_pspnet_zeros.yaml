# cfg_sample_pspnet_zeros.yaml

padding_mode: 'zeros' # 'zeros', 'reflect', 'replicate', 'circular', 'partial', 'cap_pretrain', 'cap_train' or 'pp-pad'

# path for PSPNet.py
dataset: './dataset/VOCdevkit/VOC2012/'
pretrain: ['ADE', './weights/pspnet50_ADE20K.pth']
#pretrain: ['VOC', './weights/pspnet_zeros_160.pth'] #for pp-pad, partial as pretrain model with 0 padding
#pretrain: ['VOC', './outputs/pspnet_cap_pretrain_160.pth'] # for cap_train. weight file by cap_pretrain
outputs: './outputs/'

# training parameters
num_epochs: 160
num_epoch_offset: 0 # If the training is resumed from previous training, the number of epochs in the previous training should be set here. It only affects the output weight filename.
val_output_interval: 5
batch_size: 6
batch_multiplier: 4
optimizer: 'sgd' # 'adam' for cap_pretrain, 'sgd' for others
excluding_val100: True # excluding evaluation data (val100) from validation data in training

# path for segment_val.py
val_images: './val_100.csv'
#weights: ['VOC', './outputs/pspnet_zeros_160.pth']
weights: ['VOC', './outputs/pspnet_zeros_best.pth']
# '_best.pth' for excluding_val100 = True 
# '_(num_epochs+num_epoch_offset).pth' for excluding_val100 = False

# image sizes
input_size: 475 # 512 for CAP, 475 for others
expanded_size: 1050 # input image is first expanded to expanded_size, and then crop the image in input_size.
patch_stride: 47

# dataset info
color_mean: [0.485, 0.456, 0.406]
color_std: [0.229, 0.224, 0.225]
